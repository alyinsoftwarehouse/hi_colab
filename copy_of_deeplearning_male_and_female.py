# -*- coding: utf-8 -*-
"""Copy of DeepLearning Male and Female.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d9dcDZlExOTbFb7EGCagei40MfCHDsQ_

DataSet

https://www.kaggle.com/datasets/ashwingupta3012/male-and-female-faces-dataset?select=Male+and+Female+face+dataset

# **Importing Library**
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import matplotlib.image as mimg
import tensorflow as tf
from tensorflow import keras
import cv2
import PIL
from PIL import Image
import kagglehub

# Download latest version
path = kagglehub.dataset_download("ashwingupta3012/male-and-female-faces-dataset")
# /root/.cache/kagglehub/datasets/ashwingupta3012/male-and-female-faces-dataset/versions/1
print("Path to dataset files:", path)

import os

"""# prepare for dataset"""

# Get a list of all files and directories in the 'Male Faces, Female' directory:
male_file = os.listdir('/root/.cache/kagglehub/datasets/ashwingupta3012/male-and-female-faces-dataset/versions/1/Male and Female face dataset/Male Faces')
female_file = os.listdir('/root/.cache/kagglehub/datasets/ashwingupta3012/male-and-female-faces-dataset/versions/1/Male and Female face dataset/Female Faces')

# Print the number of male and female images found:
print("Number of Male Images = ", len(male_file))
print("Number of Female Images = ", len(female_file))

# Assign labels to the images: 1 for male and 0 for female
male_label = [1]*len(male_file)
female_label = [0]*len(female_file)

# Combine male and female labels into a single list
labels = male_label + female_label
print(labels[:5])  # Print the first 5 labels
print(labels[-5:])  # Print the last 5 labels

# Read and display a sample male image
img = mimg.imread("/root/.cache/kagglehub/datasets/ashwingupta3012/male-and-female-faces-dataset/versions/1/Male and Female face dataset/Male Faces/1 (1005).jpg")
plot = plt.imshow(img)
plt.show()

# Read and display a sample female image
img=mimg.imread("/root/.cache/kagglehub/datasets/ashwingupta3012/male-and-female-faces-dataset/versions/1/Male and Female face dataset/Female Faces/0 (10).jpg")
plot=plt.imshow(img)
plt.show()

# Initialize an empty list to store image data (features) Male Female
data=[]

# Define the path to the directory containing male face images
male_path='/root/.cache/kagglehub/datasets/ashwingupta3012/male-and-female-faces-dataset/versions/1/Male and Female face dataset/Male Faces'

# Loop through each file in the male face images directory
for file in os.listdir(male_path):
    file_path = os.path.join(male_path, file) # Construct the full file path

    # Check if the file path points to a file (and not a directory)
    if os.path.isfile(file_path):
        image = Image.open(file_path) # Open the image file
        image = image.resize((128, 128))# Resize the image to 128x128 pixels
        image = image.convert('RGB') # Convert the image to RGB mode
        image = np.array(image) # Convert the image to a numpy array
        data.append(image)# Append the image data to the list


# Loop through each file in the female face images directory
female_path='/root/.cache/kagglehub/datasets/ashwingupta3012/male-and-female-faces-dataset/versions/1/Male and Female face dataset/Female Faces'

# Loop through each file in the female face images directory
for file in os.listdir(female_path):
    file_path = os.path.join(female_path, file)# Construct the full file path

    # Check if the file path points to a file (and not a directory)
    if os.path.isfile(file_path):
        image = Image.open(file_path) # Open the image file
        image = image.resize((128, 128)) # Resize the image to 128x128 pixels
        image = image.convert('RGB') # Convert the image to RGB mode
        image = np.array(image) # Convert the image to a numpy array
        data.append(image) # Append the image data to the list



# Print the number of images in the data list
print(len(data))
print(len(labels))

data[0].shape # Print the shape of the first image in the data list

"""# Convert to numpy array"""

### Convert to numpy array
X=np.array(data)
Y=np.array(labels)

X.shape,Y.shape


x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.1,random_state=2)

x_train_scl=x_train/255
x_test_scl=x_test/255

"""# Model"""

# Define the CNN model
model = keras.Sequential([
    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(128, 128, 3)),  # First convolutional layer
    keras.layers.MaxPooling2D(pool_size=(2, 2)),  # First max pooling layer

    keras.layers.Flatten(),  # Flatten the input

    keras.layers.Dense(128, activation='relu'),  # First dense layer
    keras.layers.Dropout(0.50),  # Dropout layer to prevent overfitting

    keras.layers.Dense(64, activation='relu'),  # Second dense layer
    keras.layers.Dropout(0.50),  # Dropout layer to prevent overfitting

    keras.layers.Dense(2, activation='sigmoid')  # Output layer with sigmoid activation
    ])

# Compile the model with the Adam optimizer, sparse categorical crossentropy loss, and accuracy metric
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model on the training data with a validation split of 10% and for 10 epochs
Model=model.fit(x_train_scl,y_train,validation_split=0.1,epochs=10)


# Evaluate the model on the test data
loss, acc = model.evaluate(x_test_scl, y_test)
print('The Accuracy = ', int(acc * 100), '%')

# Store the training history
h = Model

# Plot the training and validation loss
plt.plot(h.history['loss'], label='train loss')
plt.plot(h.history['val_loss'], label='validation loss')
plt.legend()
plt.show()

# Plot the training and validation accuracy
plt.plot(h.history['accuracy'], label='train accuracy')
plt.plot(h.history['val_accuracy'], label='validation accuracy')
plt.legend()
plt.show()

"""# Test the model with a new input image and predict the gender

"""

# Add this line at the top of your script with other imports
import matplotlib.image as mimg
import matplotlib.pyplot as plt # Import matplotlib.pyplot as plt
import cv2 # Import the OpenCV library

def predict_gender(image_path):
    # Read and display the input image
    img = mimg.imread(image_path)
    plt.imshow(img)
    plt.show()

    # Preprocess the input image
    img = cv2.resize(img, (128, 128))  # Resize the image to 128x128 pixels
    img = img / 255  # Normalize the image data
    img = np.reshape(img, [1, 128, 128, 3])  # Reshape the image to match the input shape of the model

    # Generate predictions for the input image
    prediction = model.predict(img)
    print(prediction)

    # Get the predicted label (0 for female, 1 for male)
    input_pred_label = np.argmax(prediction)
    print(input_pred_label)

    # Print the predicted gender
    if input_pred_label == 1:
        print('The person in the image is Male')
    else:
        print('The person in the image is Female')

# Prompt the user to enter the image path and predict gender
input_image = input("Enter the image path: ")
predict_gender(input_image)